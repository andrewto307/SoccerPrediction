{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VohVDEHlJ63G",
        "outputId": "8f79cb3d-e9dd-4c5f-fa06-ec2c4d000bfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H1gg4MGrJjfn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUYnDTR6Jjfp"
      },
      "source": [
        "# <h1 style='font-size:30px;'>Data Featuring</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZpGL8yMJjfr"
      },
      "source": [
        "# <h2 style='font-size:25px;'>Import</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jH2aOhalJjft"
      },
      "outputs": [],
      "source": [
        "X_train_full = pd.read_csv(\"/content/drive/My Drive/SoccerPrediction/data/X_train.csv\", index_col=0)\n",
        "X_test_full  = pd.read_csv(\"/content/drive/My Drive/SoccerPrediction/data/X_test.csv\", index_col=0)\n",
        "\n",
        "\n",
        "y_train = pd.read_csv(\"/content/drive/My Drive/SoccerPrediction/data/y_train.csv\", index_col=0).squeeze()\n",
        "y_test  = pd.read_csv(\"/content/drive/My Drive/SoccerPrediction/data/y_test.csv\", index_col=0).squeeze()\n",
        "\n",
        "# Make stripped-down versions for the model\n",
        "non_features = [\"Div\", \"Date\",\n",
        "                \"HomeTeam_ShotOnTarget\", \"AwayTeam_ShotOnTarget\"]\n",
        "\n",
        "X_train_features = X_train_full.drop(columns=non_features)\n",
        "X_test_features  = X_test_full.drop(columns=non_features)\n",
        "\n",
        "# Save the feature order from the stripped-down version\n",
        "feature_columns = X_train_features.columns\n",
        "feature_columns.to_series(name=\"feature\").to_csv(\"/content/drive/My Drive/SoccerPrediction/data/feature_columns.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e07BuAaoJjfu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "feat_order = pd.read_csv(\"/content/drive/My Drive/SoccerPrediction/data/feature_columns.csv\")[\"feature\"].tolist()\n",
        "\n",
        "def align_features(df: pd.DataFrame, feat_order: list[str]) -> pd.DataFrame:\n",
        "    # add any missing training columns as zeros\n",
        "    missing = [c for c in feat_order if c not in df.columns]\n",
        "    if missing:\n",
        "        df = df.copy()\n",
        "        for c in missing:\n",
        "            df[c] = 0.0\n",
        "\n",
        "    # drop any extras not used in training\n",
        "    extra = [c for c in df.columns if c not in feat_order]\n",
        "    if extra:\n",
        "        df = df.drop(columns=extra, errors=\"ignore\")\n",
        "\n",
        "    # put in the exact training order\n",
        "    df = df.reindex(columns=feat_order, fill_value=0.0)\n",
        "    return df\n",
        "\n",
        "# build the actual matrices the model will see\n",
        "X_train = align_features(X_train_features, feat_order)\n",
        "X_test  = align_features(X_test_features,  feat_order)\n",
        "\n",
        "# optional safety check\n",
        "assert list(X_train.columns) == feat_order == list(X_test.columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50rIvYwVJjfv"
      },
      "source": [
        "# <h2 style='font-size:25px;'>Probabilisitc Data Selection</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC_nK2H4Jjfw",
        "outputId": "798829a5-aefe-4901-a229-66c7d828af4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       group     brier\n",
            "0  consensus  0.557498\n",
            "6    odds_WH  0.583697\n",
            "8   odds_PSC  0.584901\n",
            "7    odds_VC  0.585204\n",
            "4    odds_BW  0.587706\n",
            "5    odds_IW  0.589967\n",
            "1  odds_B365  0.863573\n",
            "2    odds_PS  0.865276\n",
            "3   odds_Max  0.872169\n"
          ]
        }
      ],
      "source": [
        "def brier_score_multi(p, y):\n",
        "    Y = pd.get_dummies(y).reindex(columns=[0,1,2], fill_value=0).values\n",
        "    return float(np.mean(np.sum((p - Y)**2, axis=1)))\n",
        "\n",
        "def group_brier_scores(X, y):\n",
        "    rows = []\n",
        "    # consensus: probabilities already\n",
        "    if set(['pH_mean','pD_mean','pA_mean']).issubset(X.columns):\n",
        "        P = X[['pA_mean','pD_mean','pH_mean']].values  # order: 0,1,2\n",
        "        P = np.clip(P, 1e-6, 1-1e-6)\n",
        "        P = P / P.sum(axis=1, keepdims=True)\n",
        "        rows.append({'group':'consensus', 'brier': brier_score_multi(P, y)})\n",
        "    # raw odds approximate probabilities via 1/odds then renormalize\n",
        "    triplets = [('B365A','B365D','B365H'), ('PSA','PSD','PSH'), ('MaxA','MaxD','MaxH'), (\"BWH\",\"BWD\",\"BWA\"), ( \"IWH\",\"IWD\",\"IWA\"),\n",
        "                (\"WHH\",\"WHD\",\"WHA\"), (\"VCH\",\"VCD\",\"VCA\"), (\"PSCH\",\"PSCD\",\"PSCA\")]\n",
        "    for nameA,nameD,nameH in triplets:\n",
        "        if {nameA,nameD,nameH}.issubset(X.columns):\n",
        "            P = 1.0 / X[[nameA,nameD,nameH]].values\n",
        "            P = np.clip(P, 1e-6, None)\n",
        "            P = P / P.sum(axis=1, keepdims=True)\n",
        "            rows.append({'group': f'odds_{nameH[:-1]}', 'brier': brier_score_multi(P, y)})\n",
        "    return pd.DataFrame(rows).sort_values('brier')\n",
        "\n",
        "brier_df = group_brier_scores(X_train, y_train)\n",
        "print(brier_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js5nUfB4Jjfz"
      },
      "source": [
        "Drop bad odds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HcNqwdZCJjfz"
      },
      "outputs": [],
      "source": [
        "exclude = [\"B365H\",\"B365D\",\"B365A\", \"PSH\",\"PSD\",\"PSA\", \"MaxH\",\"MaxD\",\"MaxA\"]\n",
        "X_train = X_train.drop(columns=exclude)\n",
        "X_test = X_test.drop(columns=exclude)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES8fDbruJjf0"
      },
      "source": [
        "# <h2 style='font-size:25px;'>Data Selection</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iEBMbrmnJjf0"
      },
      "outputs": [],
      "source": [
        "# ---- Define feature groups ----\n",
        "\n",
        "# Form features\n",
        "form_features = [\n",
        "    \"HomeTeam_points\", \"AwayTeam_points\",\n",
        "    \"HomeTeam_avg_goal_diff\", \"AwayTeam_avg_goal_diff\"\n",
        "]\n",
        "\n",
        "# Raw bookmaker odds (all H/D/A triplets)\n",
        "bookmaker_odds = [\n",
        "    \"BWH\",\"BWD\",\"BWA\",\n",
        "    \"IWH\",\"IWD\",\"IWA\",\n",
        "    \"WHH\",\"WHD\",\"WHA\",\n",
        "    \"VCH\",\"VCD\",\"VCA\",\n",
        "    \"PSCH\",\"PSCD\",\"PSCA\"\n",
        "]\n",
        "\n",
        "# Overrounds (one per bookmaker set)\n",
        "overrounds = [\n",
        "    \"B365_overround\",\"BW_overround\",\"IW_overround\",\"WH_overround\",\n",
        "    \"VC_overround\",\"Max_overround\",\"PS_overround\",\"PSC_overround\"\n",
        "]\n",
        "\n",
        "# Elo ratings\n",
        "elo_features = [\"home_elo\",\"away_elo\",\"elo_diff\"]\n",
        "\n",
        "# Consensus features\n",
        "consensus_features = [\"pH_mean\",\"pD_mean\",\"pA_mean\",\"overround_mean\",\"overround_std\"]\n",
        "\n",
        "# Engineered extras\n",
        "engineered_features = [\"home_adv\",\"draw_tightness\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mwkvf_pJjf0"
      },
      "source": [
        "# <h3 style='font-size:20px;'>Informative groups</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7FTi5l0Jjf1",
        "outputId": "0cb94e29-494f-4cb2-d891-e704401fb62a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            group  features   mi_mean  mi_median  mi_top3_sum\n",
            "1  bookmaker_odds        15  0.079875   0.100196     0.346286\n",
            "4       consensus         3  0.080426   0.107707     0.241277\n",
            "3             elo         3  0.059961   0.048379     0.179883\n",
            "5      engineered         2  0.065186   0.065186     0.130372\n",
            "0            form         4  0.023051   0.024665     0.084605\n",
            "2      overrounds         8  0.011276   0.011363     0.063325\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def group_mutual_info(X, y, groups):\n",
        "    scores = []\n",
        "    for gname, feats in groups.items():\n",
        "        feats = [f for f in feats if f in X.columns]\n",
        "        if not feats:\n",
        "            continue\n",
        "        mi = mutual_info_classif(X[feats], y, random_state=42, discrete_features=False)\n",
        "        scores.append({\n",
        "            'group': gname,\n",
        "            'features': len(feats),\n",
        "            'mi_mean': float(np.mean(mi)),\n",
        "            'mi_median': float(np.median(mi)),\n",
        "            'mi_top3_sum': float(np.sum(np.sort(mi)[-3:])),\n",
        "        })\n",
        "    return pd.DataFrame(scores).sort_values(['mi_top3_sum','mi_mean'], ascending=False)\n",
        "\n",
        "groups = {\n",
        "    'form': form_features,\n",
        "    'bookmaker_odds': bookmaker_odds,\n",
        "    'overrounds': overrounds,\n",
        "    'elo': elo_features,\n",
        "    'consensus': consensus_features,\n",
        "    'engineered': engineered_features\n",
        "}\n",
        "\n",
        "mi_df = group_mutual_info(X_train, y_train, groups)\n",
        "print(mi_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxwiN2utJjf2"
      },
      "source": [
        "# <h3 style='font-size:20px;'>Group redundancy</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0mv3KG0Jjf2",
        "outputId": "7f6f7353-f846-4012-ff6a-daa73db73e60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            group  intragroup_corr_mean\n",
            "0            form              0.309717\n",
            "1  bookmaker_odds              0.659672\n",
            "2      overrounds              0.528862\n",
            "3             elo              0.474944\n",
            "4       consensus              0.531874\n",
            "5      engineered              0.330012\n"
          ]
        }
      ],
      "source": [
        "def group_redundancy(X, groups):\n",
        "    rows = []\n",
        "    for gname, feats in groups.items():\n",
        "        feats = [f for f in feats if f in X.columns]\n",
        "        if len(feats) < 2:\n",
        "            rows.append({'group': gname, 'intragroup_corr_mean': 0.0})\n",
        "            continue\n",
        "        corr = X[feats].corr().abs()\n",
        "        upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
        "        mean_corr = upper.stack().mean() if upper.size else 0.0\n",
        "        rows.append({'group': gname, 'intragroup_corr_mean': float(mean_corr)})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "redundancy_df = group_redundancy(X_train, groups)\n",
        "print(redundancy_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij3fiS0OJjf3"
      },
      "source": [
        "# <h3 style='font-size:20px;'>Temporal Stability</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyRdSoGHJjf3",
        "outputId": "8ab8f10d-8370-4100-b411-f03e910a13a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "form: features=4, used=4, psi_mean=0.0149\n",
            "bookmaker_odds: features=15, used=15, psi_mean=0.0750\n",
            "overrounds: features=8, used=8, psi_mean=4.3166\n",
            "elo: features=3, used=3, psi_mean=0.1937\n",
            "consensus: features=3, used=3, psi_mean=0.0850\n",
            "engineered: features=2, used=2, psi_mean=0.1131\n",
            "            group  psi_mean  features  used\n",
            "0            form  0.014941         4     4\n",
            "1  bookmaker_odds  0.075031        15    15\n",
            "4       consensus  0.084992         3     3\n",
            "5      engineered  0.113055         2     2\n",
            "3             elo  0.193702         3     3\n",
            "2      overrounds  4.316615         8     8\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def psi_with_common_bins(a, b, bins=10):\n",
        "    a = pd.Series(a, dtype='float64').dropna()\n",
        "    b = pd.Series(b, dtype='float64').dropna()\n",
        "    if len(a) < 20 or len(b) < 20:\n",
        "        return 0.0\n",
        "    s = pd.concat([a, b])\n",
        "    if s.nunique(dropna=True) <= 2 or s.std() == 0:\n",
        "        return 0.0\n",
        "\n",
        "    qs = np.linspace(0, 1, bins + 1)\n",
        "    edges = np.unique(np.nanquantile(s, qs))\n",
        "    if len(edges) < 3:\n",
        "        return 0.0\n",
        "\n",
        "    ca = pd.cut(a, edges, include_lowest=True)\n",
        "    cb = pd.cut(b, edges, include_lowest=True)\n",
        "\n",
        "    pa = ca.value_counts(normalize=True, sort=False)\n",
        "    pb = cb.value_counts(normalize=True, sort=False)\n",
        "\n",
        "    idx = pa.index.union(pb.index)\n",
        "    pa = pa.reindex(idx, fill_value=0).astype('float64') + 1e-6\n",
        "    pb = pb.reindex(idx, fill_value=0).astype('float64') + 1e-6\n",
        "\n",
        "    return float(np.sum((pa - pb) * np.log(pa / pb)))\n",
        "\n",
        "def group_stability_no_date_common_bins(X, groups, split_ratio=0.7, bins=10, verbose=False):\n",
        "    n = len(X)\n",
        "    cut = int(n * split_ratio)\n",
        "    early, late = X.iloc[:cut], X.iloc[cut:]\n",
        "\n",
        "    # keep only numeric columns once to avoid repeated inference\n",
        "    numeric_cols = set(X.select_dtypes(include=[np.number]).columns)\n",
        "\n",
        "    rows = []\n",
        "    for gname, feats in groups.items():\n",
        "        feats = [f for f in feats if f in X.columns]\n",
        "        feats = [f for f in feats if f in numeric_cols]  # ensure numeric\n",
        "        psis, used = [], 0\n",
        "\n",
        "        for f in feats:\n",
        "            a = pd.to_numeric(early[f], errors='coerce')\n",
        "            b = pd.to_numeric(late[f], errors='coerce')\n",
        "            if a.dropna().empty or b.dropna().empty:\n",
        "                continue\n",
        "            try:\n",
        "                psis.append(psi_with_common_bins(a.values, b.values, bins=bins))\n",
        "                used += 1\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        psi_mean = float(np.mean(psis)) if used > 0 else 0.0  # default to 0 (stable) if none usable\n",
        "        if verbose:\n",
        "            print(f\"{gname}: features={len(feats)}, used={used}, psi_mean={psi_mean:.4f}\")\n",
        "\n",
        "        rows.append({'group': gname, 'psi_mean': psi_mean, 'features': len(feats), 'used': used})\n",
        "\n",
        "    return pd.DataFrame(rows).sort_values('psi_mean')\n",
        "\n",
        "# Usage\n",
        "groups = {\n",
        "    'form': form_features,\n",
        "    'bookmaker_odds': bookmaker_odds,\n",
        "    'overrounds': overrounds,\n",
        "    'elo': elo_features,\n",
        "    'consensus': consensus_features,\n",
        "    'engineered': engineered_features\n",
        "}\n",
        "stability_df = group_stability_no_date_common_bins(X_train, groups, split_ratio=0.7, bins=10, verbose=True)\n",
        "print(stability_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydNSClRpJjf4"
      },
      "source": [
        "# <h3 style='font-size:20px;'>Cross Group Correlation</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSZxQhxnJjf5",
        "outputId": "50799c1f-6df1-45f7-efdc-4e7a28748845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                g1              g2  mean_abs_corr\n",
            "1             form      overrounds       0.023592\n",
            "5   bookmaker_odds      overrounds       0.039066\n",
            "10      overrounds       consensus       0.039583\n",
            "11      overrounds      engineered       0.046445\n",
            "9       overrounds             elo       0.104737\n",
            "4             form      engineered       0.376694\n",
            "2             form             elo       0.387839\n",
            "0             form  bookmaker_odds       0.400544\n",
            "3             form       consensus       0.402658\n",
            "13             elo      engineered       0.575139\n"
          ]
        }
      ],
      "source": [
        "def cross_group_corr(X, groups):\n",
        "    # mean absolute correlation between every pair of groups\n",
        "    names = list(groups.keys())\n",
        "    data = []\n",
        "    for i in range(len(names)):\n",
        "        for j in range(i+1, len(names)):\n",
        "            gi = [f for f in groups[names[i]] if f in X.columns]\n",
        "            gj = [f for f in groups[names[j]] if f in X.columns]\n",
        "            if not gi or not gj:\n",
        "                continue\n",
        "            corr = X[gi+gj].corr().abs().loc[gi, gj].values\n",
        "            data.append({'g1':names[i], 'g2':names[j], 'mean_abs_corr': float(np.nanmean(corr))})\n",
        "    return pd.DataFrame(data).sort_values('mean_abs_corr')\n",
        "\n",
        "overlap_df = cross_group_corr(X_train, groups)\n",
        "print(overlap_df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oPhmoSGJjf6"
      },
      "source": [
        "# <h3 style='font-size:20px;'>Rank Group</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yIxtPBPaJjf6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def rank_groups_multi(mi_df, redundancy_df, overlap_df, stability_df,\n",
        "                      mi_col=\"mi_top3_sum\",\n",
        "                      weights=None,          # e.g. {\"mi\":2, \"redundancy\":1, \"overlap\":1, \"stability\":1}\n",
        "                      sort_by=\"overall\"):    # \"overall\", \"mi\", \"redundancy\", \"overlap\", or \"stability\"\n",
        "    \"\"\"\n",
        "    Combine group diagnostics and produce ranks per criterion (and optional overall rank).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mi_df : DataFrame with columns [\"group\", mi_col] where mi_col is e.g. \"mi_top3_sum\"\n",
        "    redundancy_df : DataFrame with columns [\"group\", \"intragroup_corr_mean\"]\n",
        "    overlap_df : DataFrame with columns [\"g1\",\"g2\",\"mean_abs_corr\"] (pairwise group overlaps)\n",
        "    stability_df : DataFrame with columns [\"group\",\"psi_mean\"]\n",
        "    mi_col : str, column name in mi_df to use for MI ranking\n",
        "    weights : dict or None, weights for overall rank (keys: \"mi\",\"redundancy\",\"overlap\",\"stability\")\n",
        "    sort_by : str, which rank to sort by (\"overall\" requires weights)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    DataFrame with raw metrics, ranks per criterion, and optional overall rank.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Cross-group overlap → per-group mean overlap (symmetrize pairs) ---\n",
        "    if overlap_df is not None and not overlap_df.empty:\n",
        "        og = pd.concat([\n",
        "            overlap_df.rename(columns={\"g1\": \"group\", \"g2\": \"other\"}),\n",
        "            overlap_df.rename(columns={\"g2\": \"group\", \"g1\": \"other\"})\n",
        "        ], ignore_index=True)\n",
        "        cross_mean = (og.groupby(\"group\")[\"mean_abs_corr\"]\n",
        "                        .mean()\n",
        "                        .rename(\"crossgroup_corr_mean\")\n",
        "                        .reset_index())\n",
        "    else:\n",
        "        cross_mean = pd.DataFrame(columns=[\"group\", \"crossgroup_corr_mean\"])\n",
        "\n",
        "    # --- Merge everything on 'group' ---\n",
        "    cols_mi = [\"group\", mi_col]\n",
        "    cols_rd = [\"group\", \"intragroup_corr_mean\"]\n",
        "    cols_st = [\"group\", \"psi_mean\"]\n",
        "\n",
        "    df = (mi_df[cols_mi]\n",
        "            .merge(redundancy_df[cols_rd], on=\"group\", how=\"outer\")\n",
        "            .merge(cross_mean, on=\"group\", how=\"outer\")\n",
        "            .merge(stability_df[cols_st], on=\"group\", how=\"outer\"))\n",
        "\n",
        "    # Helper to rank while pushing NaNs to the bottom (worst)\n",
        "    def _rank(series, ascending):\n",
        "        s = series.copy()\n",
        "        if s.isna().any():\n",
        "            fill = (s.max() + 1) if ascending else (s.min() - 1)\n",
        "            s = s.fillna(fill)\n",
        "        return s.rank(ascending=ascending, method=\"min\")\n",
        "\n",
        "    # --- Per-criterion ranks ---\n",
        "    df[\"rank_mi\"]          = _rank(df[mi_col], ascending=False)              # higher MI is better\n",
        "    df[\"rank_redundancy\"]  = _rank(df[\"intragroup_corr_mean\"], ascending=True)\n",
        "    df[\"rank_overlap\"]     = _rank(df[\"crossgroup_corr_mean\"], ascending=True)\n",
        "    df[\"rank_stability\"]   = _rank(df[\"psi_mean\"], ascending=True)\n",
        "\n",
        "    # --- Optional overall rank (weighted sum of ranks; lower = better) ---\n",
        "    if weights:\n",
        "        w_mi  = float(weights.get(\"mi\", 1.0))\n",
        "        w_rd  = float(weights.get(\"redundancy\", 1.0))\n",
        "        w_ov  = float(weights.get(\"overlap\", 1.0))\n",
        "        w_ps  = float(weights.get(\"stability\", 1.0))\n",
        "        df[\"overall_rank_score\"] = (\n",
        "            w_mi*df[\"rank_mi\"] +\n",
        "            w_rd*df[\"rank_redundancy\"] +\n",
        "            w_ov*df[\"rank_overlap\"] +\n",
        "            w_ps*df[\"rank_stability\"]\n",
        "        )\n",
        "        df[\"rank_overall\"] = df[\"overall_rank_score\"].rank(ascending=True, method=\"min\")\n",
        "\n",
        "    # --- Sorting ---\n",
        "    sort_map = {\n",
        "        \"overall\": \"rank_overall\",\n",
        "        \"mi\": \"rank_mi\",\n",
        "        \"redundancy\": \"rank_redundancy\",\n",
        "        \"overlap\": \"rank_overlap\",\n",
        "        \"stability\": \"rank_stability\",\n",
        "    }\n",
        "    sort_col = sort_map.get(sort_by, \"rank_mi\")\n",
        "    if sort_by == \"overall\" and not weights:\n",
        "        sort_col = \"rank_mi\"  # fallback if weights not provided\n",
        "\n",
        "    # Nice column order\n",
        "    out_cols = [\"group\", mi_col, \"intragroup_corr_mean\", \"crossgroup_corr_mean\", \"psi_mean\",\n",
        "                \"rank_mi\", \"rank_redundancy\", \"rank_overlap\", \"rank_stability\"]\n",
        "    if weights:\n",
        "        out_cols += [\"overall_rank_score\", \"rank_overall\"]\n",
        "\n",
        "    return df[out_cols].sort_values(sort_col, ascending=True).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAEmDXSlJjf7",
        "outputId": "04067922-91c5-4ebc-c272-8b938881d302"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            group  mi_top3_sum  intragroup_corr_mean  crossgroup_corr_mean  \\\n",
            "0            form     0.084605              0.309717              0.318265   \n",
            "1  bookmaker_odds     0.346286              0.659672              0.480782   \n",
            "2      engineered     0.130372              0.330012              0.462187   \n",
            "3       consensus     0.241277              0.531874              0.482342   \n",
            "4             elo     0.179883              0.474944              0.463766   \n",
            "5      overrounds     0.063325              0.528862              0.050685   \n",
            "\n",
            "   psi_mean  rank_mi  rank_redundancy  rank_overlap  rank_stability  \\\n",
            "0  0.014941      5.0              1.0           2.0             1.0   \n",
            "1  0.075031      1.0              6.0           5.0             2.0   \n",
            "2  0.113055      4.0              2.0           3.0             4.0   \n",
            "3  0.084992      2.0              5.0           6.0             3.0   \n",
            "4  0.193702      3.0              3.0           4.0             5.0   \n",
            "5  4.316615      6.0              4.0           1.0             6.0   \n",
            "\n",
            "   overall_rank_score  rank_overall  \n",
            "0                14.0           1.0  \n",
            "1                15.0           2.0  \n",
            "2                17.0           3.0  \n",
            "3                18.0           4.0  \n",
            "4                18.0           4.0  \n",
            "5                23.0           6.0  \n"
          ]
        }
      ],
      "source": [
        "# Choose weights (tweak as you like)\n",
        "weights = {\"mi\": 2.0, \"redundancy\": 1.0, \"overlap\": 1.0, \"stability\": 1.0}\n",
        "\n",
        "ranked = rank_groups_multi(\n",
        "    mi_df=mi_df,\n",
        "    redundancy_df=redundancy_df,\n",
        "    overlap_df=overlap_df,\n",
        "    stability_df=stability_df,   # from your PSI-with-common-bins function\n",
        "    mi_col=\"mi_top3_sum\",\n",
        "    weights=weights,\n",
        "    sort_by=\"overall\"            # or \"mi\"/\"redundancy\"/\"overlap\"/\"stability\"\n",
        ")\n",
        "print(ranked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_sr5RQ0bJjf8"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "feat_cats  = [\"HomeTeam\", \"AwayTeam\"]\n",
        "feat_nums  = form_features\n",
        "feat_all   = feat_cats + feat_nums + bookmaker_odds\n",
        "\n",
        "Xtr = X_train[feat_all].copy()\n",
        "Xte = X_test[feat_all].copy()\n",
        "ytr, yte = y_train, y_test\n",
        "\n",
        "for c in feat_cats:\n",
        "    Xtr[c] = Xtr[c].astype(str)\n",
        "    Xte[c] = Xte[c].astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SqvnHB_TJjf8"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from collections import Counter\n",
        "\n",
        "# Define feature groups\n",
        "feat_cats = [\"HomeTeam\", \"AwayTeam\"]\n",
        "feat_nums = form_features\n",
        "feat_all = feat_cats + feat_nums + bookmaker_odds\n",
        "\n",
        "# Prepare data\n",
        "Xtr = X_train[feat_all].copy()\n",
        "Xte = X_test[feat_all].copy()\n",
        "ytr, yte = y_train, y_test\n",
        "\n",
        "# Ensure categorical features are strings\n",
        "for c in feat_cats:\n",
        "    Xtr[c] = Xtr[c].astype(str)\n",
        "    Xte[c] = Xte[c].astype(str)\n",
        "\n",
        "# --- ALWAYS encode categorical features first ---\n",
        "encoders = {}\n",
        "Xtr_enc = Xtr.copy()\n",
        "Xte_enc = Xte.copy()\n",
        "\n",
        "for c in feat_cats:\n",
        "    le = LabelEncoder()\n",
        "    # Fit on training data only, transform both train and test\n",
        "    Xtr_enc[c] = le.fit_transform(Xtr[c])\n",
        "    Xte_enc[c] = le.transform(Xte[c])  # Use transform, not fit_transform\n",
        "    encoders[c] = le"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ84KzdtJjf8",
        "outputId": "61b469bf-0ba4-47c1-d7c1-99758c4ba606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before SMOTE: Counter({2: 2013, 0: 1178, 1: 989})\n",
            "After SMOTE: Counter({2: 2013, 0: 2013, 1: 2013})\n"
          ]
        }
      ],
      "source": [
        "# Get indices of categorical columns for SMOTENC\n",
        "cat_idx = [Xtr_enc.columns.get_loc(c) for c in feat_cats]\n",
        "\n",
        "# --- Apply SMOTENC ---\n",
        "smote = SMOTENC(\n",
        "    categorical_features=cat_idx,\n",
        "    sampling_strategy=\"not majority\",  # upsample draws & away, keep home\n",
        "    random_state=42\n",
        ")\n",
        "Xtr_bal, ytr_bal = smote.fit_resample(Xtr_enc, ytr)\n",
        "\n",
        "print(\"Before SMOTE:\", Counter(ytr))\n",
        "print(\"After SMOTE:\", Counter(ytr_bal))\n",
        "\n",
        "# --- For CatBoost: Keep encoded features ---\n",
        "# CatBoost works with encoded categorical features\n",
        "Xtr_final = pd.DataFrame(Xtr_bal, columns=Xtr_enc.columns)\n",
        "Xte_final = Xte_enc.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "Xtr_bal, ytr_bal = shuffle(Xtr_bal, ytr_bal, random_state=42)"
      ],
      "metadata": {
        "id": "2jUMdSMAgbcu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bqPy9DbSJjgB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, precision_score\n",
        "\n",
        "def run_model(classifier, param_grid, X_train, y_train, X_test, y_test):\n",
        "\n",
        "    grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid, scoring='balanced_accuracy',\n",
        "                               cv=5, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    model = grid_search.best_estimator_\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"Test Set Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "    return grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZvzGKZVKRHO",
        "outputId": "c84b0ddf-6ea2-49c5-a35a-785bd2fa3efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skorch\n",
            "  Downloading skorch-1.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from skorch) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from skorch) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from skorch) (1.16.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.12/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from skorch) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.0->skorch) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.0->skorch) (3.6.0)\n",
            "Downloading skorch-1.2.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.1/263.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: skorch\n",
            "Successfully installed skorch-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install skorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "5zuAIV63fAUe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "j2QKxyB8KYI0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "# Convert to tensors\n",
        "Xtr = torch.tensor(np.asarray(Xtr_enc), dtype=torch.float32)\n",
        "ytr_t = torch.tensor(np.asarray(ytr), dtype=torch.long)\n",
        "Xte = torch.tensor(np.asarray(Xte_enc), dtype=torch.float32)\n",
        "yte_t = torch.tensor(np.asarray(yte), dtype=torch.long)\n",
        "\n",
        "train_ds = TensorDataset(Xtr, ytr_t)\n",
        "test_ds = TensorDataset(Xte, yte_t)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(Xtr, ytr_t), batch_size=512, shuffle=True)\n",
        "test_loader  = DataLoader(TensorDataset(Xte, yte_t), batch_size=256, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ndfQpq8zLS-P"
      },
      "outputs": [],
      "source": [
        "input_dim = Xtr.shape[1]\n",
        "num_classes = int(ytr_t.max().item() + 1)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_in, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, d_out)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7MDQWWBc6EH",
        "outputId": "8b2a7221-1875-49ea-cea5-5d00ad5b2943"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MLP(input_dim, num_classes).to(device)\n",
        "\n",
        "epochs = 50\n",
        "class_weights = torch.tensor([1.0, 1.5, 1.0], dtype=torch.float32, device=device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-5)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss = 0.0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * xb.size(0)"
      ],
      "metadata": {
        "id": "ZpaBDRnxc7wR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_probs = []\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        preds = probs.argmax(dim=1)\n",
        "        correct += (preds == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "        all_probs.append(probs.cpu())\n",
        "        all_preds.append(preds.cpu())\n",
        "\n",
        "proba = torch.cat(all_probs, dim=0).numpy()\n",
        "y_pred = torch.cat(all_preds, dim=0).numpy()\n",
        "\n",
        "print(f\"Test Set Accuracy: {accuracy_score(yte, y_pred):.2f}\")\n",
        "print(classification_report(yte, y_pred, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0Ny-eFic9_k",
        "outputId": "d692b0e3-a8e4-497c-e84e-ede62cd5ecb7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Accuracy: 0.54\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.40      0.46        47\n",
            "           1       0.40      0.24      0.30        50\n",
            "           2       0.58      0.80      0.67        83\n",
            "\n",
            "    accuracy                           0.54       180\n",
            "   macro avg       0.50      0.48      0.48       180\n",
            "weighted avg       0.52      0.54      0.51       180\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.jit.script(model).save(\"mlp_model.ts\")"
      ],
      "metadata": {
        "id": "0RYfnFfpdwSJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model = torch.jit.load(\"mlp_model.ts\", map_location=\"cpu\")\n",
        "print(\"Loaded successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7IMtAf2zrGJ",
        "outputId": "260da0c7-d90e-4a6d-e12b-8734a74e4ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X2YdlJfCzxcP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}